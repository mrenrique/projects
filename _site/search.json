[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/making-a-word-cloud-by-scraping-an-article/index.html#tldr",
    "href": "posts/making-a-word-cloud-by-scraping-an-article/index.html#tldr",
    "title": "Making a Word Cloud in an image‚Äôs shape by Scraping an Article",
    "section": "TL;DR ü§ì",
    "text": "TL;DR ü§ì\nHave you ever crossed some blog post, video or presentation having A fun way to show & analize which are the most relevant topics(repeated words) on a text. Bellow I show you some examples whe can create, it‚Äôs like art made out of words üé®\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/making-a-word-cloud-by-scraping-an-article/index.html#installing-libraries",
    "href": "posts/making-a-word-cloud-by-scraping-an-article/index.html#installing-libraries",
    "title": "Making a Word Cloud in an image‚Äôs shape by Scraping an Article",
    "section": "Installing Libraries ‚úîÔ∏è",
    "text": "Installing Libraries ‚úîÔ∏è\nFirst, you need to install all libraries you‚Äôll be using.\n\n!pip install numpy\n!pip install matplotlib\n!pip install newspaper3k\n!pip install pillow\n!pip install wordcloud\n!pip install nltk\n\nprint('Library installation Done!')\n\nCollecting newspaper3k\n  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 211 kB 7.6 MB/s \nRequirement already satisfied: lxml&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\nRequirement already satisfied: Pillow&gt;=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\nCollecting feedparser&gt;=5.2.1\n  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81 kB 10.0 MB/s \nRequirement already satisfied: python-dateutil&gt;=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.2)\nRequirement already satisfied: requests&gt;=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\nCollecting jieba3k&gt;=0.35.1\n  Downloading jieba3k-0.35.1.zip (7.4 MB)\n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.4 MB 60.7 MB/s \nRequirement already satisfied: nltk&gt;=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\nCollecting feedfinder2&gt;=0.0.4\n  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\nCollecting cssselect&gt;=0.9.2\n  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: beautifulsoup4&gt;=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\nCollecting tinysegmenter==0.3\n  Downloading tinysegmenter-0.3.tar.gz (16 kB)\nRequirement already satisfied: PyYAML&gt;=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\nCollecting tldextract&gt;=2.0.1\n  Downloading tldextract-3.1.2-py2.py3-none-any.whl (87 kB)\n     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87 kB 5.8 MB/s \nRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2&gt;=0.0.4-&gt;newspaper3k) (1.15.0)\nCollecting sgmllib3k\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.10.0-&gt;newspaper3k) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.10.0-&gt;newspaper3k) (2021.10.8)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.10.0-&gt;newspaper3k) (1.24.3)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.10.0-&gt;newspaper3k) (2.10)\nCollecting requests-file&gt;=1.4\n  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\nRequirement already satisfied: filelock&gt;=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract&gt;=2.0.1-&gt;newspaper3k) (3.4.2)\nBuilding wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n  Building wheel for tinysegmenter (setup.py) ... done\n  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13553 sha256=73e9156b3836ce85dc512439196c449be3d5d33749708372688c3f5d99f1a059\n  Stored in directory: /root/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n  Building wheel for feedfinder2 (setup.py) ... done\n  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3357 sha256=fe3990b9a89a29307f18a4767d156083b809112c9ca71e5ef2bbb556ddbd874e\n  Stored in directory: /root/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n  Building wheel for jieba3k (setup.py) ... done\n  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=86ab131c0f61eeaef932b8967c1915eaaabc4a1089ea070652c21631f839e9b4\n  Stored in directory: /root/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n  Building wheel for sgmllib3k (setup.py) ... done\n  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=9ad6b6bbe0b981e0262c6294017917f7b9cb32e8af7463272df81aaf6f7f2001\n  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\nSuccessfully built tinysegmenter feedfinder2 jieba3k sgmllib3k"
  },
  {
    "objectID": "posts/making-a-word-cloud-by-scraping-an-article/index.html#importing-libraries",
    "href": "posts/making-a-word-cloud-by-scraping-an-article/index.html#importing-libraries",
    "title": "Making a Word Cloud in an image‚Äôs shape by Scraping an Article",
    "section": "Importing Libraries üß∞",
    "text": "Importing Libraries üß∞\n\nfrom newspaper import Article\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, ImageColorGenerator\n\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\nTrue"
  },
  {
    "objectID": "posts/making-a-word-cloud-by-scraping-an-article/index.html#step-01-getting-the-corpus-from-an-article",
    "href": "posts/making-a-word-cloud-by-scraping-an-article/index.html#step-01-getting-the-corpus-from-an-article",
    "title": "Making a Word Cloud in an image‚Äôs shape by Scraping an Article",
    "section": "Step 01: Getting the Corpus from an Article üìù",
    "text": "Step 01: Getting the Corpus from an Article üìù\n\narticle = Article('https://www.repsol.pe/es/sala-prensa/notas-prensa/comunicado.cshtml')\narticle.download()\narticle.parse()\n\n\nGenerate a Simple Word Cloud Image\n\n# Generate a word cloud image\nwc = WordCloud()\nwc.generate(article.text)\n\n# Display the generated image:\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nGenerate a Customized Word Cloud Image\n\nstopwords = set(stopwords.words('spanish', 'english'))\n\nstopwords.update(['ello', 'cinco', 'd√≠a'])\n\nConverting an image to a numpy array results in an array containing a sequence of values that each represent an individual pixel in the image.\n\nmask = np.array(Image.open('repsol.jpg'))\n# mask = np.array(Image.open('pedro-castillo.jpg'))\n\nwc = WordCloud(stopwords=stopwords,\n               background_color=\"white\",\n               max_words=2000,\n               mask=mask,\n               )\n\nwc.generate(article.text)\n\n# Display the generated image:\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\nmask = np.array(Image.open('repsol.jpg'))\n# mask = np.array(Image.open('pedro-castillo.jpg'))\n\nwc = WordCloud(stopwords=stopwords,\n               background_color=\"white\",\n               max_words=2000,\n               mask=mask,\n               max_font_size=256,\n            #    random_state=42,\n            #    width=mask.shape[1],\n            #    height=mask.shape[0]\n               )\n\nwc.generate(article.text)\n\n# create coloring from image\nimage_colors = ImageColorGenerator(mask)\nplt.figure(figsize=[16,14])\nplt.imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()"
  },
  {
    "objectID": "posts/making-a-word-cloud-by-scraping-an-article/index.html#references",
    "href": "posts/making-a-word-cloud-by-scraping-an-article/index.html#references",
    "title": "Making a Word Cloud in an image‚Äôs shape by Scraping an Article",
    "section": "References:",
    "text": "References:\n\nhttps://medium.com/towards-data-science/create-word-cloud-into-any-shape-you-want-using-python-d0b88834bc32\nhttps://www.repsol.pe/es/sala-prensa/notas-prensa/comunicado.cshtml"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science Projects",
    "section": "",
    "text": "Making a Word Cloud in an image‚Äôs shape by Scraping an Article\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMay 1, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nApr 28, 2024\n\n\nTristan O‚ÄôMalley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  }
]